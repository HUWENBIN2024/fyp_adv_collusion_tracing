{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "from models import VGG16Head, VGG16Tail, ResNet18Head, ResNet18Tail\n",
    "import config\n",
    "from watermark import Watermark\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bibdcalc import BIBD, BIBDParams\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--model_name', help = 'Benchmark model structure.', choices = ['VGG16', 'ResNet18'])\n",
    "# parser.add_argument('--dataset_name', help = 'Benchmark dataset used.', choices = ['CIFAR10', 'GTSRB'])\n",
    "# parser.add_argument('-k', '--num_collusion', help = 'The number of attackers (k).', type = int, default = 2)\n",
    "# parser.add_argument('-n', '--num_samples', help = 'The number of generated collusive samples.', type = int, default = 1000)\n",
    "# parser.add_argument('--attack_name', help = 'Which black-box attack', choices = [ \"Bandit\", \"NES\", \"HopSkipJump\", \"SignOPT\", \"SimBA-px\"])\n",
    "# parser.add_argument('--collusion_attack', help = 'collusion methods', choices = [ \"mean\", \"max\", \"min\", \"median\", \"negative\", \"negative_prob\"])\n",
    "# parser.add_argument('-M', '--num_models', help = 'The number of models used.', type = int, default = 100)\n",
    "# args = parser.parse_args()\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'ResNet18'\n",
    "        self.dataset_name = 'CIFAR10'\n",
    "        self.num_collusion = 2\n",
    "        self.num_samples = 500\n",
    "        self.attack_name = 'HopSkipJump'\n",
    "        self.collusion_attack = 'mean'\n",
    "        self.num_models = 10\n",
    "        self.num_obtained_adv = 1\n",
    "\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "model_dir = f'saved_models/{args.model_name}-{args.dataset_name}'\n",
    "\n",
    "total = 0\n",
    "success_num = 0\n",
    "\n",
    "prob = 0.8\n",
    "a = np.load(f\"saved_collusion_adv_examples/{args.model_name}-{args.dataset_name}/{args.num_collusion}_attackers/{args.attack_name}_{args.num_samples}_num_of_samples.npz\", allow_pickle=True)\n",
    "\n",
    "img = a['X'] # shape: n, 3, 32, 32\n",
    "img_adv = a['X_attacked_k'] # shape: k, n, 3, 32, 32\n",
    "label = a['y'] # shape: n\n",
    "head_index = a['head'] # shape: n, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cat = []\n",
    "comb_id = 0\n",
    "comb_2_comb_cat = {}\n",
    "for i in range(head_index.shape[0]):\n",
    "    if tuple(sorted(head_index[i])) in comb_2_comb_cat.keys():\n",
    "        comb_id = comb_2_comb_cat[tuple(sorted(head_index[i]))]\n",
    "    else:\n",
    "        comb_id = len(comb_2_comb_cat.keys())\n",
    "        comb_2_comb_cat[tuple(sorted(head_index[i]))] = comb_id\n",
    "    comb_cat.append(comb_id)\n",
    "comb_cat = np.array(comb_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3349.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tracing accuracy is:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adv_perturb = img_adv - img # (n, 3, 32, 32)\n",
    "\n",
    "if args.collusion_attack =='mean':\n",
    "    collusion_perturb = np.mean(adv_perturb, axis=0) # (n, 3, 32, 32)\n",
    "elif args.collusion_attack =='max':\n",
    "    collusion_perturb = np.max(adv_perturb, axis=0) \n",
    "elif args.collusion_attack =='min':\n",
    "    collusion_perturb = np.min(adv_perturb, axis=0) \n",
    "elif args.collusion_attack =='median':\n",
    "    collusion_perturb = np.median(adv_perturb, axis=0) \n",
    "elif args.collusion_attack =='negative':\n",
    "    collusion_perturb = np.max(adv_perturb, axis=0) + np.min(adv_perturb, axis=0) - np.median(adv_perturb, axis=0)\n",
    "elif args.collusion_attack =='negative_prob':\n",
    "    rand_mask = np.random.choice([1, 0], size=img.shape, p=[prob, 1-prob])\n",
    "    collusion_perturb = np.max(adv_perturb, axis=0) * rand_mask + np.min(adv_perturb, axis=0) * (1 - rand_mask)\n",
    "    collusion_perturb = collusion_perturb.astype(np.float32)\n",
    "else:\n",
    "    raise Exception(f\"Unsupported Collusion Method: {args.collusion_attack}\")\n",
    "\n",
    "img_collusion = img + collusion_perturb\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "img =  torch.from_numpy(img).to(device)\n",
    "img_adv = torch.from_numpy(img_adv).to(device)\n",
    "img_collusion = torch.from_numpy(img_collusion).to(device)\n",
    "label = torch.from_numpy(label).to(device)\n",
    "\n",
    "\n",
    "dataset = eval(f'config.{args.dataset_name}()')\n",
    "training_set, testing_set = dataset.training_set, dataset.testing_set\n",
    "num_classes = dataset.num_classes\n",
    "means, stds = dataset.means, dataset.stds\n",
    "\n",
    "\n",
    "watermarks = []\n",
    "for i in range(args.num_models):\n",
    "    watermark = np.zeros((3, 32, 32))\n",
    "    try:\n",
    "        w_ = np.load(f'saved_models/ResNet18-CIFAR10/head_{i}/watermark.npy', allow_pickle=1)\n",
    "    except:\n",
    "        print(f'load head_{i} failed')\n",
    "    watermark[w_[:,0], w_[:,1], w_[:,2]] = 1\n",
    "    watermarks.append(watermark)\n",
    "\n",
    "watermarks = np.array(watermarks).astype(np.int32)\n",
    "\n",
    "and_results = []\n",
    "dic = {}\n",
    "\n",
    "wm_combinations = itertools.combinations(watermarks, args.num_collusion)\n",
    "id_combinations = list(itertools.combinations(range(len(watermarks)), args.num_collusion))\n",
    "for (cnt, combo) in enumerate(wm_combinations):\n",
    "    combo = np.array(combo)\n",
    "    result = np.all(combo, axis=0) # elementwise and\n",
    "    if any(np.array_equal(result, arr) for arr in and_results):\n",
    "        print(\"REPEAT\")\n",
    "        raise Exception\n",
    "    dic[len(and_results)] = id_combinations[cnt]\n",
    "    and_results.append(result)\n",
    "            \n",
    "and_results = np.array(and_results)\n",
    "\n",
    "success_count = 0\n",
    "\n",
    "collusion_perturb = np.abs(collusion_perturb)\n",
    "times_of_judgement = 0\n",
    "for i in tqdm(range(0, len(img_collusion), args.num_obtained_adv)):\n",
    "    if i+args.num_obtained_adv > len(img_collusion):\n",
    "        break\n",
    "    if comb_cat[i] != comb_cat[i+args.num_obtained_adv-1]:\n",
    "        continue\n",
    "\n",
    "    obtained_perts = collusion_perturb[i:i+args.num_obtained_adv, :, :, :] # [Num_access, 3, 32, 32]\n",
    "    combined_mean = np.zeros((len(and_results),))\n",
    "    for k in range(args.num_obtained_adv):\n",
    "        pert = obtained_perts[k]\n",
    "        denom = and_results.reshape(-1, 3*32*32).sum(axis=1)\n",
    "        this_mean = ((pert.reshape(3*32*32,) * and_results.reshape(-1, 3*32*32)).sum(axis=1)) / denom\n",
    "        combined_mean += this_mean\n",
    "    \n",
    "    idx_ = combined_mean.argmin()\n",
    "    head_pred = dic[idx_]\n",
    "\n",
    "    times_of_judgement += 1\n",
    "    if tuple(sorted(head_pred)) == tuple(sorted(head_index[i])):\n",
    "        success_count += 1\n",
    "\n",
    "trace_acc = success_count / times_of_judgement\n",
    "print('the tracing accuracy is: ', trace_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
